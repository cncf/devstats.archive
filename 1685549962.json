{
  "actor": {
    "avatar_url": "https://avatars3.githubusercontent.com/u/7972724?v=4",
    "events_url": "https://api.github.com/users/moonek/events{/privacy}",
    "followers_url": "https://api.github.com/users/moonek/followers",
    "following_url": "https://api.github.com/users/moonek/following{/other_user}",
    "gists_url": "https://api.github.com/users/moonek/gists{/gist_id}",
    "gravatar_id": "",
    "html_url": "https://github.com/moonek",
    "id": 7972724,
    "login": "moonek",
    "organizations_url": "https://api.github.com/users/moonek/orgs",
    "received_events_url": "https://api.github.com/users/moonek/received_events",
    "repos_url": "https://api.github.com/users/moonek/repos",
    "site_admin": false,
    "starred_url": "https://api.github.com/users/moonek/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/moonek/subscriptions",
    "type": "User",
    "url": "https://api.github.com/users/moonek"
  },
  "created_at": "2018-06-18T08:00:48Z",
  "event": "renamed",
  "id": 1685549962,
  "issue": {
    "body": "\u003c!-- This form is for bug reports and feature requests ONLY!\r\n\r\nIf you're looking for help check [Stack Overflow](https://stackoverflow.com/questions/tagged/kubernetes) and the [troubleshooting guide](https://kubernetes.io/docs/tasks/debug-application-cluster/troubleshooting/).\r\n\r\nIf this may be security issue, please disclose it privately via https://kubernetes.io/security/.\r\n--\u003e\r\n\r\n**Is this a BUG REPORT or FEATURE REQUEST?**:\r\n\r\n/kind bug\r\n/sig scalability\r\n\r\n\r\n**What happened**:\r\nHPA not working properly when pod status `Unknown` (node failure)\r\nI confirmed in k8s `v1.10.3` that this problem has not been solved yet.\r\n\r\n**What you expected to happen**:\r\nHPA based on number of normal pods except `Unknown` pods.\r\n\r\n**How to reproduce it (as minimally and precisely as possible)**:\r\nTest yaml\r\n```\r\napiVersion: extensions/v1beta1\r\nkind: Deployment\r\nmetadata:\r\n  name: test-nginx-autoscaling\r\nspec:\r\n  replicas: 2\r\n  template:\r\n    metadata:\r\n      labels:\r\n        name: test-nginx-autoscaling\r\n    spec:\r\n      containers:\r\n      - name: test-nginx-autoscaling\r\n        image: myrepo/test-nginx:stress\r\n        ports:\r\n        - containerPort: 80\r\n        resources:\r\n          requests:\r\n            cpu: 500m\r\n            memory: 128Mi\r\n---\r\napiVersion: autoscaling/v1\r\nkind: HorizontalPodAutoscaler\r\nmetadata:\r\n  name: test-nginx-autoscaling\r\n  labels:\r\n    name: test-nginx-autoscaling\r\nspec:\r\n  scaleTargetRef:\r\n    apiVersion: apps/v1beta1\r\n    kind: Deployment\r\n    name: test-nginx-autoscaling\r\n  minReplicas: 2\r\n  maxReplicas: 4\r\n  targetCPUUtilizationPercentage: 80\r\n```\r\nInitial state\r\n```\r\nNAME                                          READY     STATUS    RESTARTS   AGE       IP              NODE\r\npo/test-nginx-autoscaling-6dcf47755f-kd64n    1/1       Running   0          1m       10.244.144.43   worker-3\r\npo/test-nginx-autoscaling-6dcf47755f-x9vk4    1/1       Running   0          1m       10.244.56.17    worker-1\r\n```\r\n\r\nIntentionally caused a `worker-1` failure\r\n```\r\nNAME       STATUS     ROLES     AGE       VERSION\r\nmaster-1   Ready      master    23d      v1.10.3\r\nmaster-2   Ready      master    23d      v1.10.3\r\nmaster-3   Ready      master    23d      v1.10.3\r\nworker-1   NotReady   \u003cnone\u003e    23d      v1.10.3\r\nworker-2   Ready      \u003cnone\u003e    23d      v1.10.3\r\nworker-3   Ready      \u003cnone\u003e    23d      v1.10.3\r\nworker-4   Ready      \u003cnone\u003e    23d      v1.10.3\r\nworker-5   Ready      \u003cnone\u003e    23d      v1.10.3\r\n```\r\n\r\nThe pod was created on the other node, and the `worker-1` pod was `Unknown`\r\n```\r\nNAME                                          READY     STATUS    RESTARTS   AGE       IP              NODE\r\npo/test-nginx-autoscaling-6dcf47755f-g8n55    1/1       Running   0          21m       10.244.176.24   worker-2\r\npo/test-nginx-autoscaling-6dcf47755f-kd64n    1/1       Running   0          14m       10.244.144.43   worker-3\r\npo/test-nginx-autoscaling-6dcf47755f-x9vk4    1/1       Unknown   0          21m       10.244.56.17    worker-1\r\n```\r\n\r\nIntentionally caused a CPU load on a particular pod.\r\n```\r\n[root@jumphost:/root] kubectl exec -it test-nginx-autoscaling-6dcf47755f-g8n55 bash\r\nroot@test-nginx-autoscaling-6dcf47755f-g8n55:/# stress -c 1\r\nstress: info: [14] dispatching hogs: 1 cpu, 0 io, 0 vm, 0 hdd\r\n```\r\n\r\nThe load continues, but there are not `3` `running` pods.\r\nThe `TARGETS` is `100%/80%`.\r\n\r\n```\r\n[root@jumphost:/root] kubectl get hpa,deploy,rs,po -owide\r\n\r\nNAME                          REFERENCE                            TARGETS      MINPODS   MAXPODS   REPLICAS   AGE\r\nhpa/test-nginx-autoscaling    Deployment/test-nginx-autoscaling    100% / 80%   2         4         2          1h\r\n\r\nNAME                             DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE       CONTAINERS\r\nIMAGES                                    SELECTOR\r\ndeploy/test-nginx-autoscaling    2         2         2            2           1h        test-nginx-autoscaling\r\nmyrepo/test-nginx:stress   name=test-nginx-autoscaling\r\n\r\n\r\nNAME                                    DESIRED   CURRENT   READY     AGE       CONTAINERS                IMAGES\r\n                                  SELECTOR\r\nrs/test-nginx-autoscaling-6dcf47755f    2         2         2         1h        test-nginx-autoscaling    myrepo/test-nginx:stress   name=test-nginx-autoscaling,pod-template-hash=2879033119\r\n\r\n\r\nNAME                                          READY     STATUS    RESTARTS   AGE       IP              NODE\r\npo/test-nginx-autoscaling-6dcf47755f-g8n55    1/1       Running   0          1h        10.244.176.24   worker-2\r\npo/test-nginx-autoscaling-6dcf47755f-kd64n    1/1       Running   0          1h        10.244.144.43   worker-3\r\npo/test-nginx-autoscaling-6dcf47755f-x9vk4    1/1       Unknown   0          1h        10.244.56.17    worker-1\r\n```\r\n\r\nThe number of `AVAILABLE` pods does not include the `Unknown` pod, the `HPA` logic seems to recognize the `Unknown` pod as a normal pod.\r\nIn addition, the `DESIRED` of deployments does not increase to `3`.\r\n\r\n\r\n\r\n**Anything else we need to know?**:\r\nIf `Unknown` pod is not generated under the same condition, it is scaled normally.\r\n```\r\npo/test-nginx2-autoscaling-775668f75f-6449z   1/1       Running   0          1m        10.244.176.26   worker-2\r\npo/test-nginx2-autoscaling-775668f75f-sb48n   1/1       Running   0          1m        10.244.144.8    worker-3\r\n```\r\n```\r\n[root@jumphost:/root kubectl exec -it test-nginx2-autoscaling-775668f75f-6449z bash\r\nroot@test-nginx2-autoscaling-775668f75f-6449z:/# stress -c 1\r\nstress: info: [20] dispatching hogs: 1 cpu, 0 io, 0 vm, 0 hdd\r\n```\r\n```\r\n[root@jumphost:/root] kubectl get hpa,deploy,rs,po -owide\r\nNAME                          REFERENCE                            TARGETS     MINPODS   MAXPODS   REPLICAS   AGE\r\nhpa/test-nginx2-autoscaling   Deployment/test-nginx2-autoscaling   66% / 80%   2         4         3          10m\r\n\r\nNAME                             DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE       CONTAINERS\r\nIMAGES                                    SELECTOR\r\ndeploy/test-nginx2-autoscaling   3         3         3            3           10m        test-nginx2-autoscaling\r\nmyrepo/test-nginx:stress   name=test-nginx2-autoscaling\r\n\r\nNAME                                    DESIRED   CURRENT   READY     AGE       CONTAINERS                IMAGES\r\n                                  SELECTOR\r\nrs/test-nginx2-autoscaling-775668f75f   3         3         3         10m        test-nginx2-autoscaling   myrepo/test-nginx:stress   name=test-nginx2-autoscaling,pod-template-hash=3312249319\r\n\r\nNAME                                          READY     STATUS    RESTARTS   AGE       IP              NODE\r\npo/test-nginx2-autoscaling-775668f75f-6449z   1/1       Running   0          10m        10.244.176.26   worker-2\r\npo/test-nginx2-autoscaling-775668f75f-nb10mh   1/1       Running   0          4m        10.244.80.48    worker-4\r\npo/test-nginx2-autoscaling-775668f75f-sb48n   1/1       Running   0          10m        10.244.144.8    worker-3\r\n```\r\n\r\n\r\n\r\n**Environment**:\r\n- Kubernetes version (use `kubectl version`):\r\n```\r\nClient Version: version.Info{Major:\"1\", Minor:\"10\", GitVersion:\"v1.10.3\", GitCommit:\"2bba0127d85d5a46ab4b778548be28623b32d0b0\", GitTreeState:\"clean\", BuildDate:\"2018-05-21T09:17:39Z\", GoVersion:\"go1.9.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\nServer Version: version.Info{Major:\"1\", Minor:\"10\", GitVersion:\"v1.10.3\", GitCommit:\"2bba0127d85d5a46ab4b778548be28623b32d0b0\", GitTreeState:\"clean\", BuildDate:\"2018-05-21T09:05:37Z\", GoVersion:\"go1.9.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\r\n```\r\n- Cloud provider or hardware configuration:\r\non-premise\r\n- OS (e.g. from /etc/os-release):\r\n```\r\nCentOS Linux release 7.3.1611 (Core)\r\n```\r\n- Kernel (e.g. `uname -a`):\r\n```\r\n3.10.0-514.26.2.el7.x86_64\r\n```\r\n- Install tools:\r\nkubeadm\r\n- Others:\r\ndocker 1.12.6\r\n\r\n",
    "comments": 2,
    "comments_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/62845/comments",
    "created_at": "2018-04-19T10:31:08Z",
    "events_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/62845/events",
    "html_url": "https://github.com/kubernetes/kubernetes/issues/62845",
    "id": 315819300,
    "labels": [
      {
        "color": "e11d21",
        "id": 105146071,
        "name": "kind/bug",
        "node_id": "MDU6TGFiZWwxMDUxNDYwNzE=",
        "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/kind/bug"
      },
      {
        "color": "d2b48c",
        "id": 125010198,
        "name": "sig/scalability",
        "node_id": "MDU6TGFiZWwxMjUwMTAxOTg=",
        "url": "https://api.github.com/repos/kubernetes/kubernetes/labels/sig/scalability"
      }
    ],
    "labels_url": "https://api.github.com/repos/kubernetes/kubernetes/issues/62845/labels{/name}",
    "locked": false,
    "node_id": "MDU6SXNzdWUzMTU4MTkzMDA=",
    "number": 62845,
    "repository_url": "https://api.github.com/repos/kubernetes/kubernetes",
    "state": "open",
    "title": "HPA not working properly when pod status \"Unknown\" (node failure)",
    "updated_at": "2018-06-18T08:06:01Z",
    "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/62845",
    "user": {
      "avatar_url": "https://avatars3.githubusercontent.com/u/7972724?v=4",
      "events_url": "https://api.github.com/users/moonek/events{/privacy}",
      "followers_url": "https://api.github.com/users/moonek/followers",
      "following_url": "https://api.github.com/users/moonek/following{/other_user}",
      "gists_url": "https://api.github.com/users/moonek/gists{/gist_id}",
      "gravatar_id": "",
      "html_url": "https://github.com/moonek",
      "id": 7972724,
      "login": "moonek",
      "organizations_url": "https://api.github.com/users/moonek/orgs",
      "received_events_url": "https://api.github.com/users/moonek/received_events",
      "repos_url": "https://api.github.com/users/moonek/repos",
      "site_admin": false,
      "starred_url": "https://api.github.com/users/moonek/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/moonek/subscriptions",
      "type": "User",
      "url": "https://api.github.com/users/moonek"
    }
  },
  "rename": {
    "from": "HPA not working properly when pod status \"Unknown\"",
    "to": "HPA not working properly when pod status \"Unknown\" (node failure)"
  },
  "url": "https://api.github.com/repos/kubernetes/kubernetes/issues/events/1685549962"
}